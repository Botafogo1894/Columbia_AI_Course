{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "The focus of this week was using the Naive Bayes classifier to label text.  In this assignment, we will first build our own Naive Bayes classifier on the text samples from the lectures.  Then, we will explore the algorithm with `sklearn`.  Recall our sentences dealing with **TV** and **radio** below.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "sents = ['TV programs are not interesting -- TV is annoying.',\n",
    "'Kids like TV'\n",
    ",'We receive TV by radio waves'\n",
    ",'It is interesting to listen to the radio'\n",
    ",'On the waves, kids programs are rare.'\n",
    ",'The kids listen to the radio; it is rare.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Q1: Building a DataFrame\n",
    "\n",
    "To begin, let's organize our sentences in a familiar `DataFrame`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(sents, columns =['sents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TV programs are not interesting -- TV is annoy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kids like TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We receive TV by radio waves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is interesting to listen to the radio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On the waves, kids programs are rare.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sents\n",
       "0  TV programs are not interesting -- TV is annoy...\n",
       "1                                       Kids like TV\n",
       "2                       We receive TV by radio waves\n",
       "3           It is interesting to listen to the radio\n",
       "4              On the waves, kids programs are rare."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### PROBLEM I: Create a DataFrame with one column\n",
    "## named \"sents\", containing the six sentences above.  Save your dataframe to \n",
    "## ans_1 below.\n",
    "\n",
    "sents_df = pd.DataFrame(sents, columns =['sents'])\n",
    "ans_1 = sents_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q1",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Q2: Vectorization\n",
    "\n",
    "An important piece of the work in building a classifier will be using word counts in each class.  We will utilize the built in `CountVectorizer` from sklearn to accomplish this task.  To begin, we create a **document term matrix** that wil contain word counts for each word in the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Problem 2\n",
    "## Create a document term matrix\n",
    "## using the .fit_transform() method\n",
    "## of the CountVectorizer on your DataFrame \n",
    "## From above.  Save your results to \n",
    "## ans_2 below\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvect = CountVectorizer()\n",
    "\n",
    "term_matrix = cvect.fit_transform(ans_1['sents'])\n",
    "ans_2= term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q2",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ans_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6x20 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 38 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Q3: Back to array\n",
    "\n",
    "The results of our `CountVectorizer` transformation is a sparse matrix.  This is convenient for storing massive arrays with many zero entries as we would find with a larger corpus.  We want to examine the words and counts, so let's convert the sparse matrix back to an array using the `.asarray()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### PROBLEM III\n",
    "## After fitting your CountVectorizer\n",
    "## convert the object back to an array \n",
    "## with the .toarray() method.  Save your \n",
    "## results to ans_3\n",
    "cvect = CountVectorizer()\n",
    "fit_wrds = ans_2\n",
    "dtm = fit_wrds.toarray()\n",
    "ans_3 = dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q3",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 2, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 2, 1, 0, 0, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Q4: As a `DataFrame`\n",
    "\n",
    "Now, we can use our `CountVectorizer`'s `.get_feature_names()` method to apply titles to the columns of a `DataFrame` and the values will be those from our array above.  This time we will write a function that takes in our original text and returns a `DataFrame` with the counts of each individual word in each document, and the words as the column heading.  See the image below for the a plotted version of your final DataFrame using seaborn's `heatmap`.\n",
    "\n",
    "![](table.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### PROBLEM IV\n",
    "## Complete the function \n",
    "## make_dtmdf below\n",
    "def make_dtmdf(sents):\n",
    "    '''\n",
    "    This function will take in a list\n",
    "    of sentences and return a document\n",
    "    term matrix as a DataFrame.\n",
    "    '''\n",
    "    data = pd.DataFrame(sents, columns =['sents'])\n",
    "    cvect = CountVectorizer()\n",
    "    fit_wrds = cvect.fit_transform(data['sents'])\n",
    "    dtm = fit_wrds.toarray()\n",
    "    \n",
    "    return pd.DataFrame(dtm, columns = cvect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q4",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annoying</th>\n",
       "      <th>are</th>\n",
       "      <th>by</th>\n",
       "      <th>interesting</th>\n",
       "      <th>is</th>\n",
       "      <th>it</th>\n",
       "      <th>kids</th>\n",
       "      <th>like</th>\n",
       "      <th>listen</th>\n",
       "      <th>not</th>\n",
       "      <th>on</th>\n",
       "      <th>programs</th>\n",
       "      <th>radio</th>\n",
       "      <th>rare</th>\n",
       "      <th>receive</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>tv</th>\n",
       "      <th>waves</th>\n",
       "      <th>we</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annoying  are  by  interesting  is  it  kids  like  listen  not  on  \\\n",
       "0         1    1   0            1   1   0     0     0       0    1   0   \n",
       "1         0    0   0            0   0   0     1     1       0    0   0   \n",
       "2         0    0   1            0   0   0     0     0       0    0   0   \n",
       "3         0    0   0            1   1   1     0     0       1    0   0   \n",
       "4         0    1   0            0   0   0     1     0       0    0   1   \n",
       "5         0    0   0            0   1   1     1     0       1    0   0   \n",
       "\n",
       "   programs  radio  rare  receive  the  to  tv  waves  we  \n",
       "0         1      0     0        0    0   0   2      0   0  \n",
       "1         0      0     0        0    0   0   1      0   0  \n",
       "2         0      1     0        1    0   0   1      1   1  \n",
       "3         0      1     0        0    1   2   0      0   0  \n",
       "4         1      0     1        0    1   0   0      1   0  \n",
       "5         0      1     1        0    2   1   0      0   0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dtmdf(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Q5: Trimming the Vocabulary\n",
    "\n",
    "As we can see, our text has some unneccessary words.  For example, it won't be very important to a sentence if it contains the word \"to\" as being classified as TV or radio.  These are called *stop_words* and the `CountVectorizer` has an argument `stop_words` that we can utilize to eliminate this uninformative vocabulary.  Let's add this element to our function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### PROBLEM V\n",
    "def make_dtmdf(sents, stopwords = True):\n",
    "    '''\n",
    "    This function will take in a list\n",
    "    of sentences and return a document\n",
    "    term matrix as a DataFrame. By default,\n",
    "    it will remove the stopwords from the texts.\n",
    "    '''\n",
    "    if stopwords:\n",
    "        data = pd.DataFrame(sents, columns =['sents'])\n",
    "        cvect = CountVectorizer(stop_words = 'english')\n",
    "        fit_wrds = cvect.fit_transform(data['sents'])\n",
    "        dtm = fit_wrds.toarray()\n",
    "        final_df = pd.DataFrame(dtm, columns = cvect.get_feature_names())\n",
    "    else:\n",
    "        data = pd.DataFrame(sents, columns =['sents'])\n",
    "        cvect = CountVectorizer()\n",
    "        fit_wrds = cvect.fit_transform(data['sents'])\n",
    "        dtm = fit_wrds.toarray()\n",
    "        final_df = pd.DataFrame(dtm, columns = cvect.get_feature_names())\n",
    "        \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q5",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annoying</th>\n",
       "      <th>interesting</th>\n",
       "      <th>kids</th>\n",
       "      <th>like</th>\n",
       "      <th>listen</th>\n",
       "      <th>programs</th>\n",
       "      <th>radio</th>\n",
       "      <th>rare</th>\n",
       "      <th>receive</th>\n",
       "      <th>tv</th>\n",
       "      <th>waves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annoying  interesting  kids  like  listen  programs  radio  rare  receive  \\\n",
       "0         1            1     0     0       0         1      0     0        0   \n",
       "1         0            0     1     1       0         0      0     0        0   \n",
       "2         0            0     0     0       0         0      1     0        1   \n",
       "3         0            1     0     0       1         0      1     0        0   \n",
       "4         0            0     1     0       0         1      0     1        0   \n",
       "5         0            0     1     0       1         0      1     1        0   \n",
       "\n",
       "   tv  waves  \n",
       "0   2      0  \n",
       "1   1      0  \n",
       "2   1      1  \n",
       "3   0      0  \n",
       "4   0      1  \n",
       "5   0      0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dtmdf(sents, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Q6: Adding a Label Column\n",
    "\n",
    "Now, we add to our function to accept a list of labels for the sentences \n",
    "and return a DataFrame containing the labels for each sentence in a column titled \"label\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "def make_dtmdf(sents, labels, stopwords = True):\n",
    "    '''\n",
    "    This function will take in a list\n",
    "    of sentences and return a document\n",
    "    term matrix as a DataFrame. By default,\n",
    "    it will remove the stopwords from the texts.\n",
    "    '''\n",
    "    if stopwords:\n",
    "        data = pd.DataFrame(sents, columns =['sents'])\n",
    "        cvect = CountVectorizer(stop_words = 'english')\n",
    "        fit_wrds = cvect.fit_transform(data['sents'])\n",
    "        dtm = fit_wrds.toarray()\n",
    "        final_df = pd.DataFrame(dtm, columns = cvect.get_feature_names())\n",
    "    else:\n",
    "        data = pd.DataFrame(sents, columns =['sents'])\n",
    "        cvect = CountVectorizer()\n",
    "        fit_wrds = cvect.fit_transform(data['sents'])\n",
    "        dtm = fit_wrds.toarray()\n",
    "        final_df = pd.DataFrame(dtm, columns = cvect.get_feature_names())\n",
    "        \n",
    "    final_df['labels'] = labels\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q6",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = ['TV', 'TV', 'radio', 'radio', 'TV', 'radio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annoying</th>\n",
       "      <th>interesting</th>\n",
       "      <th>kids</th>\n",
       "      <th>like</th>\n",
       "      <th>listen</th>\n",
       "      <th>programs</th>\n",
       "      <th>radio</th>\n",
       "      <th>rare</th>\n",
       "      <th>receive</th>\n",
       "      <th>tv</th>\n",
       "      <th>waves</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>radio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>radio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>radio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annoying  interesting  kids  like  listen  programs  radio  rare  receive  \\\n",
       "0         1            1     0     0       0         1      0     0        0   \n",
       "1         0            0     1     1       0         0      0     0        0   \n",
       "2         0            0     0     0       0         0      1     0        1   \n",
       "3         0            1     0     0       1         0      1     0        0   \n",
       "4         0            0     1     0       0         1      0     1        0   \n",
       "5         0            0     1     0       1         0      1     1        0   \n",
       "\n",
       "   tv  waves  label  \n",
       "0   2      0     TV  \n",
       "1   1      0     TV  \n",
       "2   1      1  radio  \n",
       "3   0      0  radio  \n",
       "4   0      1     TV  \n",
       "5   0      0  radio  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dtmdf(sents, labels, stopwords = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = make_dtmdf(sents, labels, stopwords = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annoying</th>\n",
       "      <th>interesting</th>\n",
       "      <th>kids</th>\n",
       "      <th>like</th>\n",
       "      <th>listen</th>\n",
       "      <th>programs</th>\n",
       "      <th>radio</th>\n",
       "      <th>rare</th>\n",
       "      <th>receive</th>\n",
       "      <th>tv</th>\n",
       "      <th>waves</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annoying  interesting  kids  like  listen  programs  radio  rare  receive  \\\n",
       "0         1            1     0     0       0         1      0     0        0   \n",
       "1         0            0     1     1       0         0      0     0        0   \n",
       "4         0            0     1     0       0         1      0     1        0   \n",
       "\n",
       "   tv  waves label  \n",
       "0   2      0    TV  \n",
       "1   1      0    TV  \n",
       "4   0      1    TV  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test.label == 'TV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = (test.groupby('label').sum() + 1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans['radio'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annoying</th>\n",
       "      <th>interesting</th>\n",
       "      <th>kids</th>\n",
       "      <th>like</th>\n",
       "      <th>listen</th>\n",
       "      <th>programs</th>\n",
       "      <th>radio</th>\n",
       "      <th>rare</th>\n",
       "      <th>receive</th>\n",
       "      <th>tv</th>\n",
       "      <th>waves</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>radio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>radio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>radio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annoying  interesting  kids  like  listen  programs  radio  rare  receive  \\\n",
       "0         1            1     0     0       0         1      0     0        0   \n",
       "1         0            0     1     1       0         0      0     0        0   \n",
       "2         0            0     0     0       0         0      1     0        1   \n",
       "3         0            1     0     0       1         0      1     0        0   \n",
       "4         0            0     1     0       0         1      0     1        0   \n",
       "5         0            0     1     0       1         0      1     1        0   \n",
       "\n",
       "   tv  waves  label  \n",
       "0   2      0     TV  \n",
       "1   1      0     TV  \n",
       "2   1      1  radio  \n",
       "3   0      0  radio  \n",
       "4   0      1     TV  \n",
       "5   0      0  radio  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Q7: Computing our Priors\n",
    "\n",
    "The priors in this case deal with the probability that a text was in either label.  Assing the correct values for `P(TV)` and `P(radio)` to p_tv and p_radio respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "p_tv = 1/2\n",
    "p_radio = 1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q7",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Q8: Conditional Probabilities\n",
    "\n",
    "Recall from our lectures that the following formula yeilds the conditional probability that a given word occurs given a label.\n",
    "\n",
    "$$\\hat{P}(w | c) = \\frac{count(w, c) + 1}{count(c) + |vocabulary|}$$\n",
    "\n",
    "First, we write a function to compute the `count(w, c)` piece.  This should return a `DataFrame` as shown below.\n",
    "\n",
    "![](ans_8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "def count_w_c(dtm):\n",
    "    '''\n",
    "    This function takes in a \n",
    "    document term matrix including\n",
    "    class labels column named labels.\n",
    "    We return the count for each word given by \n",
    "    each word given a class.\n",
    "    '''\n",
    "    nominator = (dtm.groupby('labels').sum() + 1).T\n",
    "       \n",
    "    return nominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q8",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Q9: Counting labels\n",
    "\n",
    "Now, we turn our attention to the denominator.  Here, we want to get the `count(c)` term first.  This function will return the count of words in each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "def count_c(sents, labels, stopwords = True):\n",
    "    '''\n",
    "    This function takes in a list\n",
    "    of sentences, and a list of class labels.  \n",
    "    \n",
    "    It returns counts of total words in the class labels\n",
    "    in the order TV, radio.\n",
    "    '''\n",
    "    if stopwords:\n",
    "        cvect = CountVectorizer(stop_words = 'english')\n",
    "    else:\n",
    "        cvect = CountVectorizer()\n",
    "        \n",
    "    data = pd.DataFrame(sents, columns = ['sents'])\n",
    "    fit_wrds = cvect.fit_transform(data['sents'])\n",
    "    dtm = fit_wrds.toarray()\n",
    "    final_df = pd.DataFrame(dtm, columns = cvect.get_feature_names())\n",
    "        \n",
    "    final_df['labels'] = labels\n",
    "    \n",
    "    nominator = (final_df.groupby('labels').sum() + 1).T\n",
    "    tv = nominator.sum()['TV']\n",
    "    radio = nominator.sum()['radio']\n",
    "    \n",
    "    return tv, radio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 22)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_c(sents, labels, stopwords = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q9",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Q10: Conditional Probabilities\n",
    "\n",
    "Now, we want to compute the conditional probability of class inclusion given a new sentence.  This is the formula given by:\n",
    "\n",
    "$$\\hat{P}(w | c) = \\frac{count(w, c) + 1}{count(c) + |vocabulary|}$$\n",
    "\n",
    "We define a function named `conditional_probabilities` that will return a dataframe with the conditional probabilities for class inclusion of a new sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Complete the conditional_probability\n",
    "## function below that takes in a list of sentences\n",
    "## a list of labels, and a list with a new sentence\n",
    "## to be classified.  The function will return the conditional\n",
    "## probabilities for each class.\n",
    "def conditional_probabilities(sents, labels, new, stopwords = True):\n",
    "    '''\n",
    "    Use the formula above and your earlier\n",
    "    functions to compute the conditional probability\n",
    "    for each word being in each class.\n",
    "    \n",
    "    Example:\n",
    "    sents = ['Chinese Beijing Chinese',\n",
    "    'Chinese Chinese Shanghai', \n",
    "    'Chinese Macao', \n",
    "    'Tokyo Japan Chinese']\n",
    "    labels = ['c', 'c', 'c', 'j']\n",
    "    new = ['Chinese Chinese Chinese Tokyo Japan']\n",
    "    \n",
    "    ans = ans_make_dtmdf(a, ['c', 'c', 'c', 'j'], ['Chinese Chinese Chinese Tokyo Japan'])\n",
    "    \n",
    "    print(ans) --> \ta\tb\tp_w_a\tp_w_b\n",
    "            chinese\t6\t2\t0.428571\t0.222222\n",
    "            japan\t1\t2\t0.071429\t0.222222\n",
    "            tokyo\t1\t2\t0.071429\t0.222222\n",
    "    '''\n",
    "    if stopwords:\n",
    "        cvect = CountVectorizer(stop_words = 'english')\n",
    "    else:\n",
    "        cvect = CountVectorizer()\n",
    "        \n",
    "    fit_wrds = cvect.fit_transform(sents)\n",
    "    dtm = fit_wrds.toarray()\n",
    "    final_df = pd.DataFrame(dtm, columns = cvect.get_feature_names())   \n",
    "    final_df['labels'] = labels\n",
    "    \n",
    "    ans = (final_df.groupby('labels').sum() + 1).T\n",
    "    c1 = ans.sum()[0]\n",
    "    c2 = ans.sum()[1]\n",
    "    \n",
    "    new_wrd = cvect.transform(new).toarray()\n",
    "    new_df = pd.DataFrame(new_wrd, columns = cvect.get_feature_names())\n",
    "    \n",
    "    a1 = ans/c1\n",
    "    a2 = ans/c2\n",
    "    \n",
    "    vect2 = CountVectorizer(stop_words = 'english')\n",
    "    index = cvect.fit_transform(new)\n",
    "    index = cvect.get_feature_names()\n",
    "    full_df = pd.concat([ans, a1['c'], a2['j']], axis = 1)\n",
    "    full_df.columns = ['a', 'b', 'p_w_a', 'p_w_b']\n",
    "    \n",
    "    return full_df.loc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q10",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>p_w_a</th>\n",
       "      <th>p_w_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chinese</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>japan</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokyo</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         a  b     p_w_a     p_w_b\n",
       "chinese  6  2  0.428571  0.222222\n",
       "japan    1  2  0.071429  0.222222\n",
       "tokyo    1  2  0.071429  0.222222"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional_probabilities(['Chinese Beijing Chinese',\n",
    "    'Chinese Chinese Shanghai', \n",
    "    'Chinese Macao', \n",
    "    'Tokyo Japan Chinese'], ['c', 'c', 'c', 'j'], ['Chinese Chinese Chinese Tokyo Japan'], stopwords = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Q11: Completing the Task\n",
    "\n",
    "Once we have these conditional probabilities, we use them to compute the probabilities for each class by combining the priors with the conditional probabilities for each words occurrence.  For example, if we have a new sentence:\n",
    "\n",
    "`I saw the radio on the TV`\n",
    "\n",
    "we compute two probabilities.  The first is the probability this sentence comes from `TV` the second for `radio`.  These would be calculated with:\n",
    "\n",
    "$$P(c_{tv}) \\times P(radio | c_{tv}) \\times P( TV | c_{tv})$$\n",
    "\n",
    "$$P(c_{radio}) \\times P(radio | c_{radio}) \\times P( TV | c_{radio})$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### PROBLEM 11\n",
    "## Use your conditional probabilities\n",
    "## and priors to compute the class of the \n",
    "## given sentence.  Which class should we\n",
    "## label it, 'TV' or 'radio'?  Save your\n",
    "## answer to ans_11 below\n",
    "new = ['I saw the radio on the TV']\n",
    "ans_11 = 'TV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q11",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Part II: `sklearn` and Spam\n",
    "\n",
    "Shifting to an existing implementation from `sklearn`, we will work through a text classification project using a dataset from the [UCI Machine Learning Repository]( https://archive.ics.uci.edu/ml/datasets/sms+spam+collection) dealing with email spam. Our goal is to classify messages as **spam** or **ham**. \n",
    "\n",
    "```\n",
    "The collection is composed by just one text file, where each line has the correct class followed by the raw message. We offer some examples bellow: \n",
    "\n",
    "ham What you doing?how are you? \n",
    "ham Ok lar... Joking wif u oni... \n",
    "ham dun say so early hor... U c already then say... \n",
    "ham MY NO. IN LUTON 0125698789 RING ME IF UR AROUND! H* \n",
    "ham Siva is in hostel aha:-. \n",
    "ham Cos i was out shopping wif darren jus now n i called him 2 ask wat present he wan lor. Then he started guessing who i was wif n he finally guessed darren lor. \n",
    "spam FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! ubscribe6GBP/ mnth inc 3hrs 16 stop?txtStop \n",
    "spam Sunshine Quiz! Win a super Sony DVD recorder if you canname the capital of Australia? Text MQUIZ to 82277. B \n",
    "spam URGENT! Your Mobile No 07808726822 was awarded a L2,000 Bonus Caller Prize on 02/09/03! This is our 2nd attempt to contact YOU! Call 0871-872-9758 BOX95QU \n",
    "\n",
    "Note: the messages are not chronologically sorted.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "sms = pd.read_table('../resource/asnlib/public/docs/SMSSpamCollection.txt', names = ['spam', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spam                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Q12: train/test split\n",
    "\n",
    "We begin by splitting our data into a training and a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Problem 12\n",
    "## Train/Test split. Recall our target is spam!\n",
    "## Use sklearns train_test_split() with a random seed = 24\n",
    "## to split the data into training and testing set.  Save your\n",
    "## answers as X_train, X_test, y_train, y_test\n",
    "X = sms.message\n",
    "Y = sms.spam\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q12",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Q13: Vectorizer Fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### PROBLEM 13\n",
    "## Fit a CountVectorizer to the \n",
    "## train dataset saved in Q12\n",
    "cvect = CountVectorizer()\n",
    "cvect.fit(X_train)\n",
    "ans = cvect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q13",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Q14: Transform Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### PROBLEM 14\n",
    "## Using your fit CountVectorizer\n",
    "## Transform you training data and save the \n",
    "## results to X_train_cvect\n",
    "X_train_cvect = cvect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q14",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Q15: Transform Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### PROBLEM 15\n",
    "## Using the same CountVectorizer instance\n",
    "## transform your testing data and save the results\n",
    "## to X_test_cvect\n",
    "X_test_cvect = cvect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q15",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Q16: Building Model\n",
    "\n",
    "Now, we implement the Multinomial Naive Bayes estimator from `sklearn`.  This is the recommended option for textual count features.\n",
    "\n",
    "```\n",
    "The multinomial Naive Bayes classifier is suitable for classification with\n",
    "discrete features (e.g., word counts for text classification). The\n",
    "multinomial distribution normally requires integer feature counts. However,\n",
    "in practice, fractional counts such as tf-idf may also work.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "### PROBLEM 16\n",
    "## Use the Instantiated Naive Bayes Classifier \n",
    "## and fit your training data\n",
    "nbayes = MultinomialNB()\n",
    "nbayes.fit(X_train_cvect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q16",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Q17: Assessing the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### PROBLEM 17\n",
    "## Use the .score() method\n",
    "## to assess the fit on the testing\n",
    "## data.  Save your score to ans_17 below\n",
    "ans_17 = nbayes.score(X_test_cvect, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q17",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9842067480258435"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: spam, dtype: float64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.spam.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Q18: Excluding `stopwords`\n",
    "\n",
    "We didn't remove stopwords as we had in our NaiveBayes from part I.  Let's now write a function that takes in an X and y predictor and target array, and returns the score after fitting \n",
    "a `MutlinomialNB` to the vocabulary with the stopwords removed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### PROBLEM 18\n",
    "## Complete the function below\n",
    "def nbayes_fit(X, y, stopwords = True):\n",
    "    '''\n",
    "    This function takes in a pandas series of text\n",
    "    and one of a target variable.  \n",
    "    The function fits a MultinomialNB with CountVectorized\n",
    "    text having the stopwords removed.\n",
    "    '''\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state = 24)\n",
    "    \n",
    "    if stopwords:\n",
    "        cvect = CountVectorizer(stop_words = 'english')\n",
    "    else:\n",
    "        cvect = CountVectorizer()\n",
    "    \n",
    "    X_train_cvect = cvect.fit_transform(X_train)\n",
    "    X_test_cvect = cvect.transform(X_test)\n",
    "    \n",
    "    nbayes = MultinomialNB()\n",
    "    nbayes.fit(X_train_cvect, y_train)\n",
    "    \n",
    "    return nbayes.score(X_test_cvect, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q18",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9849246231155779"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbayes_fit(sms.message, sms.spam, stopwords = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Q19: Incorporating `ngrams`\n",
    "\n",
    "The `CountVectorizer` also contains an `n_gram_range` parameter that allows us to incoporporate bi-grams, tri-grams, and any range of n-grams.  We call this by using a range of values as a tuple.  Now, let's incorporate **bigrams** into our model, and see if the score improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "## Complete the function below\n",
    "def nbayes_fit(X, y, stopwords = True, ngrams = 2):\n",
    "    '''\n",
    "    This function takes in a pandas series of text\n",
    "    and one of a target variable.  \n",
    "    The function fits a MultinomialNB with CountVectorized\n",
    "    text having the stopwords removed.  We also use bigrams\n",
    "    by incorporating the ngram_range of the CountVectorizer\n",
    "    up through the ngrams argument value.  This is default to 2.(bigrams)\n",
    "    '''\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state = 24)\n",
    "    \n",
    "    if stopwords:\n",
    "        cvect = CountVectorizer(stop_words = 'english', ngram_range=(1, ngrams))\n",
    "    else:\n",
    "        cvect = CountVectorizer(ngram_range=(1, ngrams))\n",
    "    \n",
    "    X_train_cvect = cvect.fit_transform(X_train)\n",
    "    X_test_cvect = cvect.transform(X_test)\n",
    "    \n",
    "    nbayes = MultinomialNB()\n",
    "    nbayes.fit(X_train_cvect, y_train)\n",
    "    \n",
    "    return nbayes.score(X_test_cvect, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q19",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9849246231155779"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbayes_fit(X, Y, stopwords = True, ngrams = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### `tfidf` Vectorizer\n",
    "\n",
    "In addition to the `CountVectorizer` we have an option to use the **term frequency inverse document frequency** vectorization approach.  Here, rather than just pure word counts, we attempt to measure the rarity of words in the text.  From the [user guide](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction).\n",
    "\n",
    "Tf means term-frequency while tfidf means term-frequency times inverse document-frequency: \n",
    "\n",
    "$$\\text{tf-idf}(t, d) = tf(t, d) \\times idf(t)$$\n",
    "\n",
    "Using the TfidfTransformers default settings, `TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)` the term frequency, the number of times a term occurs in a given document, is multiplied with idf component, which is computed as\n",
    "\n",
    "$$\\text{idf}(t) = \\log \\frac{1 + n}{1 + df(t)} + 1$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "tfidif = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Q20: Revising Function with `tfidif`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "###PROBLEM 20\n",
    "def tfidif_bayes(X, y, stopwords = True, ngrams = 2):\n",
    "    '''\n",
    "    This function takes in a pandas series of text\n",
    "    and one of a target variable.  \n",
    "    The function fits a MultinomialNB with TfidifVectorizer\n",
    "    text having the stopwords removed.  We also use bigrams\n",
    "    by incorporating the ngram_range of the TfidfVectorizer\n",
    "    up through the ngrams argument value.  This is default to 2.(bigrams)\n",
    "    '''\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state = 24)\n",
    "    \n",
    "    if stopwords:\n",
    "        cvect = TfidfVectorizer(stop_words = 'english', ngram_range=(1, ngrams))\n",
    "    else:\n",
    "        cvect = TfidfVectorizer(ngram_range=(1, ngrams))\n",
    "    \n",
    "    X_train_cvect = cvect.fit_transform(X_train)\n",
    "    X_test_cvect = cvect.transform(X_test)\n",
    "    \n",
    "    nbayes = MultinomialNB()\n",
    "    nbayes.fit(X_train_cvect, y_train)\n",
    "    \n",
    "    return nbayes.score(X_test_cvect, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q20",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9612347451543432"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidif_bayes(X, Y, stopwords = True, ngrams = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Not bad!  We can apply many of our earlier ideas around searching for the ideal hyperparameters in order to attempt improvement.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.6]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
